# WebCrawler ğŸ•·ï¸

[![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Active-brightgreen.svg)](https://github.com/yourusername/WebCrawler)

ä¸€ä¸ªé«˜æ€§èƒ½ã€å¤šè¿›ç¨‹çš„Pythonç½‘ç»œçˆ¬è™«æ¡†æ¶ï¼Œä¸“ä¸ºå¹¶å‘æŠ“å–ç½‘é¡µæ ‡é¢˜è€Œè®¾è®¡ã€‚æ”¯æŒå†…å­˜ç›‘æ§ã€é”™è¯¯å¤„ç†å’Œæ•°æ®åˆ†æåŠŸèƒ½ã€‚
https://github.com/Fenyuan666/WebCrawler.git
## âœ¨ åŠŸèƒ½ç‰¹æ€§

- ğŸš€ **å¤šè¿›ç¨‹å¹¶å‘**: ä½¿ç”¨Pythonå¤šè¿›ç¨‹ç»•è¿‡GILé™åˆ¶ï¼Œæé«˜çˆ¬å–æ•ˆç‡
- ğŸ“Š **å†…å­˜ç›‘æ§**: å®æ—¶ç›‘æ§å†…å­˜ä½¿ç”¨æƒ…å†µï¼Œé˜²æ­¢å†…å­˜æ³„æ¼
- ğŸ” **æ™ºèƒ½è§£æ**: ä½¿ç”¨BeautifulSoup4è¿›è¡ŒHTMLè§£æï¼Œæ”¯æŒä¸­æ–‡ç¼–ç 
- ğŸ“ **è¯¦ç»†æ—¥å¿—**: å®Œæ•´çš„æ—¥å¿—è®°å½•ç³»ç»Ÿï¼Œä¾¿äºè°ƒè¯•å’Œç›‘æ§
- ğŸ“ˆ **æ•°æ®åˆ†æ**: è‡ªåŠ¨åˆ†æçˆ¬å–ç»“æœï¼Œç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
- âš¡ **é”™è¯¯å¤„ç†**: å®Œå–„çš„å¼‚å¸¸å¤„ç†æœºåˆ¶ï¼Œç¡®ä¿ç¨‹åºç¨³å®šè¿è¡Œ
- ğŸ¯ **é…ç½®çµæ´»**: æ”¯æŒè‡ªå®šä¹‰å¹¶å‘æ•°ã€è¶…æ—¶æ—¶é—´ç­‰å‚æ•°

## ğŸ› ï¸ æŠ€æœ¯æ ˆ

- **Python 3.7+**
- **requests**: HTTPè¯·æ±‚åº“
- **BeautifulSoup4**: HTMLè§£æåº“
- **multiprocessing**: å¤šè¿›ç¨‹æ”¯æŒ
- **tracemalloc**: å†…å­˜ç›‘æ§

## ğŸ“¦ å®‰è£…

### ç¯å¢ƒè¦æ±‚

- Python 3.7 æˆ–æ›´é«˜ç‰ˆæœ¬
- pip åŒ…ç®¡ç†å™¨

### å®‰è£…æ­¥éª¤

1. **å…‹éš†é¡¹ç›®**
   ```bash
   git clone https://github.com/Fenyuan666/WebCrawler.git
   cd WebCrawler
   ```

2. **åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ** (æ¨è)
   ```bash
   python -m venv myenv
   
   # Windows
   myenv\Scripts\activate
   
   # macOS/Linux
   source myenv/bin/activate
   ```

3. **å®‰è£…ä¾èµ–**
   ```bash
   pip install -r requirements.txt
   ```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬ä½¿ç”¨

1. **é…ç½®ç›®æ ‡URL**
   
   ç¼–è¾‘ `config.py` æ–‡ä»¶ï¼Œè®¾ç½®è¦çˆ¬å–çš„URLåˆ—è¡¨ï¼š
   ```python
   URLS = [
       "https://www.baidu.com",
       "https://www.google.com",
       "https://www.github.com",
       # æ·»åŠ æ›´å¤šURL...
   ]
   ```

2. **è¿è¡Œçˆ¬è™«**
   ```bash
   python main.py
   ```

### é…ç½®é€‰é¡¹

åœ¨ `config.py` ä¸­å¯ä»¥è°ƒæ•´ä»¥ä¸‹å‚æ•°ï¼š

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `NUM_PROCESSES` | 4 | å¹¶å‘è¿›ç¨‹æ•° |
| `TIMEOUT` | 5 | è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ |
| `LOG_LEVEL` | "INFO" | æ—¥å¿—çº§åˆ« |

### è¾“å‡ºç¤ºä¾‹

```
2024-01-01 12:00:00 [INFO] __main__: å¯åŠ¨çˆ¬è™«ï¼Œç›®æ ‡æ•°: 2
2024-01-01 12:00:00 [INFO] __main__: å†…å­˜ç›‘æ§å¼€å§‹
2024-01-01 12:00:01 [INFO] crawler: å¼€å§‹æŠ“å–: https://www.baidu.com
2024-01-01 12:00:01 [INFO] crawler: æˆåŠŸæŠ“å– https://www.baidu.com -> ç™¾åº¦ä¸€ä¸‹ï¼Œä½ å°±çŸ¥é“
2024-01-01 12:00:02 [INFO] analyzer: åˆ†æå®Œæˆ
2024-01-01 12:00:02 [INFO] __main__: ğŸ“Š æŠ¥å‘Š:
  total: 2
  success: 2
  failed: 0
  average_title_length: 8.5
  top_titles: ['ç™¾åº¦ä¸€ä¸‹ï¼Œä½ å°±çŸ¥é“', 'Google']
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
WebCrawler/
â”œâ”€â”€ main.py              # ä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ crawler.py           # çˆ¬è™«æ ¸å¿ƒæ¨¡å—
â”œâ”€â”€ analyzer.py          # æ•°æ®åˆ†ææ¨¡å—
â”œâ”€â”€ monitor.py           # å†…å­˜ç›‘æ§æ¨¡å—
â”œâ”€â”€ logger.py            # æ—¥å¿—é…ç½®æ¨¡å—
â”œâ”€â”€ config.py            # é…ç½®æ–‡ä»¶
â”œâ”€â”€ requirements.txt     # ä¾èµ–åŒ…åˆ—è¡¨
â”œâ”€â”€ README.md           # é¡¹ç›®è¯´æ˜æ–‡æ¡£
â”œâ”€â”€ LICENSE             # è®¸å¯è¯æ–‡ä»¶
â””â”€â”€ .gitignore          # Gitå¿½ç•¥æ–‡ä»¶
```

## ğŸ”§ æ¨¡å—è¯´æ˜

### `main.py`
- ç¨‹åºå…¥å£ç‚¹
- åè°ƒå„ä¸ªæ¨¡å—çš„å·¥ä½œ
- ç®¡ç†å¤šè¿›ç¨‹æ± 

### `crawler.py`
- æ ¸å¿ƒçˆ¬è™«åŠŸèƒ½
- HTTPè¯·æ±‚å¤„ç†
- HTMLè§£æå’Œæ ‡é¢˜æå–
- é”™è¯¯å¤„ç†æœºåˆ¶

### `analyzer.py`
- æ•°æ®åˆ†æåŠŸèƒ½
- ç»Ÿè®¡æˆåŠŸç‡ã€å¤±è´¥ç‡
- è®¡ç®—å¹³å‡æ ‡é¢˜é•¿åº¦
- ç”Ÿæˆåˆ†ææŠ¥å‘Š

### `monitor.py`
- å†…å­˜ä½¿ç”¨ç›‘æ§
- æ€§èƒ½åˆ†æ
- èµ„æºä½¿ç”¨ç»Ÿè®¡

### `logger.py`
- æ—¥å¿—ç³»ç»Ÿé…ç½®
- ç»Ÿä¸€çš„æ—¥å¿—æ ¼å¼
- å¯é…ç½®çš„æ—¥å¿—çº§åˆ«

### `config.py`
- é¡¹ç›®é…ç½®å‚æ•°
- URLåˆ—è¡¨ç®¡ç†
- ç³»ç»Ÿå‚æ•°è®¾ç½®

## ğŸ¯ é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰çˆ¬è™«é€»è¾‘

ä½ å¯ä»¥æ‰©å±• `crawler.py` ä¸­çš„ `fetch_title` å‡½æ•°æ¥å®ç°è‡ªå®šä¹‰çš„çˆ¬å–é€»è¾‘ï¼š

```python
def fetch_title(url):
    # è‡ªå®šä¹‰çˆ¬å–é€»è¾‘
    response = requests.get(url, timeout=config.TIMEOUT)
    # æ·»åŠ è‡ªå®šä¹‰å¤„ç†...
    return result
```

### æ·»åŠ æ–°çš„åˆ†æåŠŸèƒ½

åœ¨ `analyzer.py` ä¸­æ·»åŠ æ–°çš„åˆ†æå‡½æ•°ï¼š

```python
def custom_analysis(results):
    # è‡ªå®šä¹‰åˆ†æé€»è¾‘
    return analysis_result
```

### æ‰©å±•ç›‘æ§åŠŸèƒ½

å¯ä»¥ä¿®æ”¹ `monitor.py` æ¥æ·»åŠ æ›´å¤šç›‘æ§æŒ‡æ ‡ï¼š

```python
class ExtendedMonitor(MemoryMonitor):
    def __exit__(self, *args):
        # æ·»åŠ CPUä½¿ç”¨ç‡ç›‘æ§
        # æ·»åŠ ç½‘ç»œä½¿ç”¨ç›‘æ§
        super().__exit__(*args)
```

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **ç¼–ç é—®é¢˜**
   - ç¡®ä¿ç›®æ ‡ç½‘ç«™ä½¿ç”¨UTF-8ç¼–ç 
   - æ£€æŸ¥ `response.encoding` è®¾ç½®

2. **è¶…æ—¶é”™è¯¯**
   - å¢åŠ  `TIMEOUT` å€¼
   - æ£€æŸ¥ç½‘ç»œè¿æ¥

3. **å†…å­˜ä½¿ç”¨è¿‡é«˜**
   - å‡å°‘ `NUM_PROCESSES` æ•°é‡
   - æ£€æŸ¥æ˜¯å¦æœ‰å†…å­˜æ³„æ¼

4. **è¯·æ±‚è¢«æ‹’ç»**
   - æ·»åŠ è¯·æ±‚å¤´æ¨¡æ‹Ÿæµè§ˆå™¨
   - å¢åŠ è¯·æ±‚é—´éš”æ—¶é—´

### è°ƒè¯•æŠ€å·§

1. **å¯ç”¨è¯¦ç»†æ—¥å¿—**
   ```python
   LOG_LEVEL = "DEBUG"
   ```

2. **å•è¿›ç¨‹æµ‹è¯•**
   ```python
   NUM_PROCESSES = 1
   ```

3. **æ£€æŸ¥ç½‘ç»œè¿æ¥**
   ```bash
   ping target-website.com
   ```

## ğŸ¤ è´¡çŒ®æŒ‡å—

æˆ‘ä»¬æ¬¢è¿æ‰€æœ‰å½¢å¼çš„è´¡çŒ®ï¼

### å¦‚ä½•è´¡çŒ®

1. Fork æœ¬é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ Pull Request

### å¼€å‘ç¯å¢ƒè®¾ç½®

1. å®‰è£…å¼€å‘ä¾èµ–
   ```bash
   pip install -r requirements.txt
   pip install pytest black flake8
   ```

2. è¿è¡Œæµ‹è¯•
   ```bash
   pytest tests/
   ```

3. ä»£ç æ ¼å¼åŒ–
   ```bash
   black .
   flake8 .
   ```

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸ™ è‡´è°¢

- [requests](https://requests.readthedocs.io/) - HTTPåº“
- [BeautifulSoup4](https://www.crummy.com/software/BeautifulSoup/) - HTMLè§£æåº“
- [Python multiprocessing](https://docs.python.org/3/library/multiprocessing.html) - å¤šè¿›ç¨‹æ”¯æŒ

## ğŸ“ è”ç³»æ–¹å¼

- é¡¹ç›®ä¸»é¡µ: [https://github.com/yourusername/WebCrawler](https://github.com/yourusername/WebCrawler)
- é—®é¢˜åé¦ˆ: [Issues](https://github.com/yourusername/WebCrawler/issues)
- é‚®ç®±: your.email@example.com

---

â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ªæ˜Ÿæ ‡ï¼
